{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "583545d1-324b-447e-932a-b81fd1a131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in anaconda commandprompt:\n",
    "    #conda install pytorch torchvision cpuonly -c pytorch\n",
    "    \n",
    "    \n",
    "    #pip install opencv\n",
    "    \n",
    "    \n",
    "    #pip install jupyterlab ultralytics\n",
    "    # or\n",
    "    #pip install ultralytics\n",
    "    or\n",
    "    #pip install ultralytics==8.2.76\n",
    "\n",
    "\n",
    "# you can train your own model in yolo and use it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf6488e-4e47-4954-b4d8-68bf056a617a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207da993-2bed-4c15-82c7-2d97142b283c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661de4ea-96f3-4bab-9b83-67498f80a481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6269939-5537-40cb-bc12-b17564a86ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b71ef-81c4-4647-b4a3-cf106e426528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f80bcf03-f30f-4666-ab18-ce4f2783bb85",
   "metadata": {},
   "source": [
    "# Base detection and tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39eeeb-6273-44e1-bc9d-724028edc0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f81e7d0-1271-495d-8ab3-fe72b13e67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video_Path = r'./videos/video360p.mp4'\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model= YOLO('yolov8n.pt')\n",
    "Video_Path = r\"C:\\Users\\KeyhanAzarjoo\\Python Training Code\\Python-Yolo8-object-Detection\\videos\\video1111.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9bcb959-3161-47f0-984e-4faf72355778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basedetectionandtracker(Path):\n",
    "    cap = cv2.VideoCapture(Path)\n",
    "    ret = True\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        clear_output(wait=True)\n",
    "        if ret:\n",
    "            \n",
    "            # detect objects\n",
    "            # track object\n",
    "            results = model.track(frame, persist=True)\n",
    "        \n",
    "            # plot results    \n",
    "            frame_ = results[0].plot()\n",
    "        \n",
    "            # visualize\n",
    "            cv2.imshow('frame', frame_)\n",
    "            if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c59e2-8c4a-4e67-a3ce-8f29cc1b969e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060e7c46-1225-43f0-b35b-d626909bbee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 persons, 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "basedetectionandtracker(Video_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d160dd-9523-4202-aeda-5c1264ab6aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b7011-8a0b-4e59-8953-df0a78b5753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106898a-4546-43eb-88dd-4507424166c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21576d95-2878-4f2f-8ca4-52a1813f901b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d8809-5837-4b6d-84b2-b9f2835e91b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d716cbdf-d3af-42e5-b159-4305e1754a49",
   "metadata": {},
   "source": [
    "# view webcam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ac991-c20a-4437-a027-00efeb36da92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429b55bd-444f-436f-a78d-83fba09d3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4139bc5e-ef0a-4b16-bf2b-b99fc20bb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # 0 is the webcam\n",
    "ret = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008e16d-2ea4-416f-addb-368cf09b7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb838b5-a0e4-4116-84db-d5bc3809e1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a66fc-e9cd-49c3-bfde-e1307766aafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a4db1-b44e-4237-88a0-eeb9354ba27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d1b34-12c8-430b-823c-312c9d54bede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba66ac-805c-4ef9-9ce5-8b06cce57cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39a738de-7a83-4a7f-a821-2ce27943419d",
   "metadata": {},
   "source": [
    "# Detect and Track any object in YOLO8 from file and webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56578071-e7f8-4ffc-bea5-22cb6d471e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e61054-8a6a-4db2-9b97-640152a69dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import torch\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Function to process video with optimizations\n",
    "def process_video(video_path, frame_skip=1, ConfidenceThreshold = 0.75, ShowVideo = False, Resolution = (0, 0)):\n",
    "    # Load video\n",
    "    model= YOLO('yolov8n.pt')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        clear_output(wait=True)\n",
    "        if not ret:\n",
    "            break\n",
    "         # Skip frames if needed\n",
    "        if frame_count % frame_skip != 0:\n",
    "             frame_count += 1\n",
    "             continue\n",
    "\n",
    "        # Optionally resize the frame for faster processing\n",
    "        if Resolution != (0,0):\n",
    "            frame = cv2.resize(frame, Resolution)   \n",
    "\n",
    "        \n",
    "        # Use the model to track objects in the frame\n",
    "        results = model.track(frame, show=False, persist=True, conf=ConfidenceThreshold)\n",
    "        if ShowVideo:\n",
    "            annotated_frame = results[0].plot()\n",
    "            cv2.imshow(\"FRAME\",annotated_frame)\n",
    "            del annotated_frame\n",
    "\n",
    "        del frame \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "# Example usage\n",
    "# Load a lighter YOLO model (e.g., YOLOv8-tiny) and set the video path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405d62c-4e8b-4bd7-9518-b229485a3b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6eb3d8-5469-48c9-86e9-0a65c5864a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874d8695-5bd6-4a27-9d0b-a890a90dc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Path = r\"C:\\Users\\KeyhanAzarjoo\\Python Training Code\\Python-Yolo8-object-Detection\\test.MP4\"\n",
    "test = process_video(Video_Path, frame_skip=2, ConfidenceThreshold = 0.25, ShowVideo = True, Resolution = (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10deb46e-0cba-41be-b9e4-56bda49972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aff9f-4c56-4878-9773-fed7aa04683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Path = 0 # it take a bit time\n",
    "test = process_video(Video_Path, frame_skip=2, ConfidenceThreshold = 0.25, ShowVideo = True, Resolution = (0, 0))\n",
    "#test = process_video(Video_Path, frame_skip=2, ConfidenceThreshold = 0.25, ShowVideo = True, Resolution = (1080, 720)) # to chenge the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063df206-527b-4796-8747-1f7e706472f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b71ee-7c22-4a20-b003-a71b8266d9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4451ba8-1b33-40fe-817e-8769248ec2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29fef1-e8d0-4842-af76-513636087d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dd807-bd5f-4958-96d5-bafcdcbc45f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5bd60d4-7eef-4c50-9816-28c4454cccb0",
   "metadata": {},
   "source": [
    "# Detect and Track any object in YOLO8 from stream Url Like Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c7af2-5028-4f1f-aa78-25994a9988b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7250311-d279-4c34-93a0-c7684fe9117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from vidgear.gears import CamGear   \n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# Function to process video with optimizations\n",
    "def process_live_video(video_url, frame_skip=1, ConfidenceThreshold = 0.75, ShowVideo = False, Resolution = (0, 0)):\n",
    "    stream = CamGear(source=video_url, stream_mode = True, logging=False).start()\n",
    "    # Load video\n",
    "    model= YOLO('yolov8n.pt')\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        frame = stream.read()\n",
    "        clear_output(wait=True)\n",
    "        if frame is None:\n",
    "            break\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        if frame_count % frame_skip != 0:\n",
    "             frame_count += 1\n",
    "             continue\n",
    "            \n",
    "        # Optionally resize the frame for faster processing\n",
    "        if Resolution != (0,0):\n",
    "            frame = cv2.resize(frame, Resolution)   \n",
    "\n",
    "        results = model.track(frame, show=False, persist=True, conf=ConfidenceThreshold)\n",
    "        if ShowVideo:\n",
    "            annotated_frame = results[0].plot()\n",
    "            cv2.imshow(\"FRAME\",annotated_frame)\n",
    "            del annotated_frame\n",
    "\n",
    "        del frame \n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "# Example usage\n",
    "# Load a lighter YOLO model (e.g., YOLOv8-tiny) and set the video path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d213e-5fd5-4f23-ab90-e36f03469e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d795d75-0ea8-44c0-9c15-b3c0eba4d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Path_from_youtube = r\"https://www.youtube.com/watch?v=jMVYZ9uMkwI\"\n",
    "test = process_live_video(Video_Path_from_youtube, frame_skip=3, ConfidenceThreshold = 0.25 ,ShowVideo = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a05319-307f-460d-90b2-ecedccff097d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ef0f6-0a18-4c68-8817-9fa08fdaa328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a6b45-5fa4-4a49-a546-9cb483881a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11be6b-7226-4a63-8d78-618814a59fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1791c98-27a4-4208-b5b1-90858ccd9ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c58cfaae-fcdc-42b1-8f50-fe08fbec61c0",
   "metadata": {},
   "source": [
    "# Extract and data result from YOLO8 from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba93f49-bcf5-4699-9c5d-b1c835d20ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e999875-1296-42b1-a2f5-b1ee06da246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to process video with optimizations\n",
    "def process_video_GetResults(video_path, frame_skip=1, ConfidenceThreshold = 0.75, ShowVideo = False, Resolution = (0, 0), excel_file='predictions.xlsx'):\n",
    "    \n",
    "    # Load video\n",
    "    model= YOLO('yolov8n.pt')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    all_detections = []  # To store all detections\n",
    "\n",
    "    \n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #clear_output(wait=True)\n",
    "        if not ret:\n",
    "            break\n",
    "         # Skip frames if needed\n",
    "        if frame_count % frame_skip != 0:\n",
    "             frame_count += 1\n",
    "             continue\n",
    "\n",
    "        # Optionally resize the frame for faster processing\n",
    "        if Resolution != (0,0):\n",
    "            frame = cv2.resize(frame, Resolution)   \n",
    "        current_time = datetime.now()    \n",
    "        \n",
    "        # Use the model to track objects in the frame\n",
    "        results = model.track(frame, show=False, persist=True, conf=ConfidenceThreshold)\n",
    "        print('=================================================================')\n",
    "\n",
    "        detections = extract_detections(results, current_time, frame_count, model.names)\n",
    "        all_detections.extend(detections)  # Add detections to the main list\n",
    "       \n",
    "        print('=================================================================')\n",
    "        \n",
    "        if ShowVideo:\n",
    "            annotated_frame = results[0].plot()\n",
    "            cv2.imshow(\"FRAME\",annotated_frame)\n",
    "            del annotated_frame\n",
    "\n",
    "        del frame \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    df = pd.DataFrame(all_detections)\n",
    "\n",
    "    # Append to an existing Excel file or create a new one\n",
    "    with pd.ExcelWriter(excel_file, mode='a', if_sheet_exists='overlay', engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name='Detections')\n",
    "# Example usage\n",
    "# Load a lighter YOLO model (e.g., YOLOv8-tiny) and set the video path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dc94d2-10b9-4116-864e-0adb6ba79b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_detections(results,timestamp, frame_number, class_names):\n",
    "    detections = []\n",
    "\n",
    "    # Loop over each result to extract details\n",
    "    for r in results:\n",
    "        for det in r.boxes:\n",
    "            # Get class index and map it to class name\n",
    "            class_index = int(det.cls[0])\n",
    "            class_name = class_names[class_index]\n",
    "            \n",
    "            detection = {\n",
    "                'Time': timestamp.strftime('%Y-%m-%d %H:%M:%S'),  # Format time as string\n",
    "                'FrameNumber': frame_number,   # Use frame number as timestamp; can be modified to use actual time\n",
    "                'Object': class_name,  # Class name (e.g., person, car)\n",
    "                'ID': int(det.id[0]) if det.id is not None else None,  # Unique ID for tracking\n",
    "                'Confidence': float(det.conf[0])  # Confidence score\n",
    "            }\n",
    "            detections.append(detection)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210e542-5930-4ddd-b2cd-2293a746bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_Path = r\"C:\\Users\\KeyhanAzarjoo\\Python Training Code\\Python-Yolo8-object-Detection\\video360p.mp4\"\n",
    "Save_Path = 0\n",
    "test = process_video_GetResults(Video_Path, frame_skip=60, ConfidenceThreshold = 0.50, ShowVideo = True, Resolution = (0, 0), excel_file = Save_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d005f3-23ba-432d-8b2a-ffe28b5ecc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293dcc-6dc8-4150-9423-444c7fed7ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2da8-8cf3-4a64-8883-3a94cd263737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841da838-0886-4ec5-b787-15aedf0841a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094f7ff-47be-4903-abbe-d3639bf0112b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266c0e38-8ca9-46f6-b2e6-6bde0863f526",
   "metadata": {},
   "source": [
    "# write predicted results in a Textfile with CSV format Each some second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34c4b7-f32b-431e-9020-30164baafc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "80b6ae81-e077-4dd2-be89-33978dfa183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract detected objects and their details\n",
    "def extract_detections(results, timestamp, class_names):\n",
    "    detections = []\n",
    "    for r in results:\n",
    "        for det in r.boxes:\n",
    "            class_index = int(det.cls[0])\n",
    "            class_name = class_names[class_index]\n",
    "            detection = {\n",
    "                'Time': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'Object': class_name,\n",
    "                'ID': int(det.id[0]) if det.id is not None else None,\n",
    "                'Confidence': float(det.conf[0])\n",
    "            }\n",
    "            detections.append(detection)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7656b808-2fc7-4daf-bd31-48667a930a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append data to a CSV file\n",
    "def append_to_csv(detections, csv_file):\n",
    "    df = pd.DataFrame(detections)\n",
    "    if not os.path.exists(csv_file):\n",
    "        df.to_csv(csv_file, index=False, mode='w')\n",
    "    else:\n",
    "        df.to_csv(csv_file, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c83eb-3f77-4a93-af02-2729d93adfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "\n",
    "# Main function to process video and save results to CSV\n",
    "def process_video_GetResults(video_path, frame_skip=1, ConfidenceThreshold=0.75, ShowVideo=False, Resolution=(0, 0), csv_file='predictions.csv', save_interval=1):\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    frame_count = 0\n",
    "    all_detections = []\n",
    "    last_save_time = start_time\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip != 0:\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        if Resolution != (0, 0):\n",
    "            frame = cv2.resize(frame, Resolution)\n",
    "\n",
    "        timestamp = start_time + timedelta(seconds=frame_count / frame_rate)\n",
    "        results = model.track(frame, show=False, persist=True, conf=ConfidenceThreshold)\n",
    "        detections = extract_detections(results, timestamp, model.names)\n",
    "        all_detections.extend(detections)\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        if (current_time - last_save_time).total_seconds() >= save_interval:\n",
    "            append_to_csv(all_detections, csv_file)\n",
    "            last_save_time = current_time\n",
    "            all_detections = []\n",
    "\n",
    "        if ShowVideo:\n",
    "            annotated_frame = results[0].plot()\n",
    "            cv2.imshow(\"FRAME\", annotated_frame)\n",
    "            del annotated_frame\n",
    "\n",
    "        del frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if all_detections:\n",
    "        append_to_csv(all_detections, csv_file)\n",
    "\n",
    "# Example usage\n",
    "Video_Path = r\"C:\\Users\\KeyhanAzarjoo\\Python Training Code\\Python-Yolo8-object-Detection\\video360p.mp4\"\n",
    "Save_Path = r\"C:\\Users\\KeyhanAzarjoo\\Python Training Code\\Python-Yolo8-object-Detection\\predictions.csv\"\n",
    "\n",
    "process_video_GetResults(Video_Path, frame_skip=30, ConfidenceThreshold=0.50, ShowVideo=True, Resolution=(0, 0), csv_file=Save_Path, save_interval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b237414-7e97-4cf7-ae69-8cedc4e223b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc3535-70db-4bd1-91ef-3ca2c51159e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ef82f-5ec8-4ccf-b55e-5210cabf57f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3586df9-9a57-4cb1-9a5e-f7d7295c019a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d5382-0c4c-4786-a7d9-5f4410edc8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b92658b-6de9-4446-a419-b83663a57d45",
   "metadata": {},
   "source": [
    "# Extract light Version (NCNN) From YOLO v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c1df15-3bd7-441d-95af-e684acfb0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a light version of ncnn from YOLO\n",
    "# Export to NCNN: Converting Your YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98bc215d-06c5-4d41-8842-5cb373f08a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can expand model compatibility and deployment flexibility by converting YOLOv8 models to NCNN format.\n",
    "\n",
    "# ncnn is a light version of your model to run on embadded system or phone or websites.\n",
    "#Embedded Systems and IoT Devices: If you find that running inference on a Raspberry Pi with the Ultralytics Guide isn't fast enough, switching to an NCNN exported model could help speed things up. NCNN is great for devices like Raspberry Pi and NVIDIA Jetson, especially in situations where you need quick processing right on the device.\n",
    "\n",
    "#Desktop and Server Deployment: Capable of being deployed in desktop and server environments across Linux, Windows, and macOS, supporting development, training, and evaluation with higher computational capacities.\n",
    "\n",
    "#reference : https://docs.ultralytics.com/integrations/ncnn/#deployment-options-with-ncnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252dec0-3f3c-40fb-98e1-5be21f42b0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea605724-11ee-472a-962d-f8fb3556b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Export the model to NCNN format\n",
    "model.export(format=\"ncnn\")  # creates '/yolov8n_ncnn_model'\n",
    "\n",
    "# Load the exported NCNN model\n",
    "ncnn_model = YOLO(\"./yolov8n_ncnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8d87b-2b3f-4708-9efe-932167c051b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343759f-903e-4172-bf1b-b7bdb860d0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb0971-4e24-43ca-845a-6e4bc8a61af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae36170-7655-42d9-956c-1ba1a2f39db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9939e-ccb2-4aeb-9b15-6edd53ff1180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e5861-5cd1-4cfe-b5bc-e3b9aace4b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
